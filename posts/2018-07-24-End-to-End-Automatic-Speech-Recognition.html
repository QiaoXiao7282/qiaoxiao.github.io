<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>End-to-End Automatic Speech Recognition</title>
        <link rel="stylesheet" href="../css/default.css" />
        <link rel="stylesheet" href="../css/syntax.css" />
        <link rel="shortcut icon" type="image/x-icon" href="../images/favicon.ico" />
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://chaoxuprime.com/mathjax_conf.js">
        </script>

    </head>

    <body>
        <header class="hide-on-print">
            <div id="blog-title">
                 <a href="../">chuan</a>
            </div>

        </header>

        <article role="main">
            <h1 id="article-title">End-to-End Automatic Speech Recognition</h1>
            <br />

<p>本文主要介绍了语音识别实现中的一些基本知识点，包括CTC，注意力机制。</p>
<h1 id="语音识别">语音识别</h1>
<p>语音识别是一个seq2seq的问题，其表达式如下： <br /><span class="math display">$$
\begin{align*}
    \mathbf{y} = \mathop{arg\max}_{x} logp(\mathbf{y}|\mathbf{x})
\end{align*}
$$</span><br /> 其中输入序列为<span class="math inline"><strong>x</strong> = (<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, ..., <em>x</em><sub><em>T</em></sub>)</span>，输出序列为<span class="math inline"><strong>y</strong> = (<em>y</em><sub>1</sub>, <em>y</em><sub>2</sub>, ..., <em>y</em><sub><em>L</em></sub>)</span>。在语音识别领域，<span class="math inline"><strong>x</strong></span>指输入的音频序列，<span class="math inline"><strong>y</strong></span>指输出的文字。我们采用encoder-decoder attention框架，在编码部分利用深度网络提取输入信号的high-level特征表达，解码部分包括RNN, Attention和CTC机制。注意力机制作为用作特征的加权，输入raw input信号在网络中完成解码输出，实现端对端的语音识别。</p>
<h1 id="ctc">CTC</h1>
<p>CTC全称Connectionist temporal Classification classification，在CTC提出之前，为了训练时序分类任务，我们往往预先将每一帧的输入数据和对应的标签对应，再采用交叉熵作为损失函数进行训练。而CTC免去了每一帧数据和标签的对应信息，只关心整体的输入和与标签是否一致。</p>
<p>解码一串语音序列，最容易想到的方法是把每一帧语音进行识别，然后再合并连续帧出现的重复字符，比如<span class="math inline">[<em>c</em>, <em>c</em>, <em>a</em>, <em>a</em>, <em>t</em>] = [<em>c</em>, <em>a</em>, <em>t</em>]</span>。但是这种方法存在两个缺点：1）无法处理无声的帧信号；2）无法处理单词里有连续重复字母的情况，例如apple。CTC解决了这个问题，它引入了一个记号，此文用<span class="math inline"><em>ϵ</em></span>表示。这一个额外的一个空白字符<span class="math inline"><em>e</em><em>p</em><em>s</em><em>i</em><em>l</em><em>o</em><em>n</em></span>被强制要求插入到帧和帧之间，在对齐时再移去，举例一些对齐的方式</p>
<center>
<img src="../images/ctc.svg" width="400">
</center>
<p><br /><span class="math display">$$
\begin{array}{lllllllll}
\hline 
 &amp;x_1 &amp;x_2 &amp;x_3 &amp;x_4 &amp;x_5 &amp;x_6 &amp;x_7 &amp;output \\
 &amp;a &amp;p &amp;\epsilon &amp;p &amp;l &amp;\epsilon &amp;e &amp;apple\\
 &amp;a &amp;\epsilon &amp;a &amp;p &amp;\epsilon &amp;l &amp;e &amp;aaple\\
\hline
\end{array}
$$</span><br /></p>
<p>我们可以写出CTC的目标函数： <br /><span class="math display">$$
\begin{align*}
\alpha_t(s) = \sum_{\substack{\pi\in N^T \\ B(\pi_{1:t})=\textbf{l}_{1:s}}}\prod_{t^\prime=1}^ty_{\pi_{t^\prime}}^{t^\prime}
\end{align*}
$$</span><br /> 即<span class="math inline"><strong>l</strong><sub>1 : <em>s</em></sub></span>为所有输入长度为<span class="math inline"><em>t</em></span>的路径的多对一映射，所有路径长度<span class="math inline"><em>t</em></span>的集合B的概率和为<span class="math inline"><em>α</em><sub><em>t</em></sub>(<em>s</em>)</span>。</p>
<p><br /><span class="math display">$$
\begin{align*}
\mathbf{l^\prime}=[\epsilon, y_1, \epsilon, y_2, ..., \epsilon, y_U, \epsilon]
\end{align*}
$$</span><br /> , 我们计<span class="math inline"><em>α</em><sub><em>s</em>, <em>t</em></sub></span>是子序列<span class="math inline"><strong>z</strong><sub>1 : <em>s</em></sub></span>在输入长度为<span class="math inline"><em>t</em></span>时的CTC score。 所以，如果我们知道了<span class="math inline"><em>t</em> − 1</span>时刻的CTC score，我们就可以递推出最后时刻的CTC score。</p>
<h2 id="ctc的概率计算">CTC的概率计算</h2>
<p>我们记没有加<span class="math inline"><em>ϵ</em></span>的序列<span class="math inline"><strong>l</strong></span>，记在每个有效字符前后加了<span class="math inline"><em>ϵ</em></span>的序列为<span class="math inline"><strong>l</strong><sup><strong>′</strong></sup></span>。我们将在下面计算得到CTC的概率递推式。</p>
<p>首先考虑初始情况。可以看出， <br /><span class="math display">$$
\begin{align*}
\alpha_1(1) &amp;= y_\epsilon^1 \\
\alpha_1(2) &amp;= y_{\textbf{l}_1}^1 \\
\alpha_1(s) &amp;= 0, \forall s &gt; 2 
\end{align*}
$$</span><br /> 即路径长度为1时，只可能是<span class="math inline"><em>ϵ</em></span>，路径长度为2时，只可能是序列<span class="math inline"><strong>l</strong></span>的第一个有效字符。</p>
<p>我们再考虑递推的关系式。CTC是基于条件独立假设，即后一帧的输出只取决于当前帧，与之前帧相互独立。在<span class="math inline"><em>t</em></span>时刻可能会出现<span class="math inline"><em>ϵ</em></span>，也可能刚好出现有效字符。</p>
<p>第一种情况下， <br /><span class="math display">$$
\begin{align*}
\alpha_t(s) = (\alpha_{t-1}(s) + \alpha_{t-1}(s-1))\cdot p_t(\mathbf{l^\prime}_{1:s}|X)
\end{align*}
$$</span><br /> 我们考虑<span class="math inline"><strong>l</strong><sup><strong>′</strong></sup><sub><em>s</em> − 1</sub></span>在<span class="math inline"><em>s</em> − 1</span>时刻无法忽略时，那么1) <span class="math inline"><strong>l</strong><sup><strong>′</strong></sup><sub><em>s</em> − 1</sub></span>可能为一个有效字符，鉴于每两个有效字符之间存在一个额外的空白字符，所以可以推出<span class="math inline"><strong>l</strong><sup><strong>′</strong></sup><sub><em>s</em></sub> = <em>ϵ</em></span>; 2) <span class="math inline"><strong>l</strong><sup><strong>′</strong></sup><sub><em>s</em> − 1</sub></span>可能为空白字符，则<span class="math inline"><strong>l</strong><sup><strong>′</strong></sup><sub><em>s</em></sub></span>和<span class="math inline"><strong>l</strong><sup><strong>′</strong></sup><sub><em>s</em> − 2</sub></span>为重复的字符。</p>
<p>第二种情况下下，前一个字符可以跳过，则这种情况下<span class="math inline"><strong>l</strong><sup><strong>′</strong></sup><sub><em>s</em> − 1</sub></span>为一个空白字符<span class="math inline"><em>ϵ</em></span>，而<span class="math inline"><strong>l</strong><sup><strong>′</strong></sup><sub><em>s</em> − 2</sub></span>和<span class="math inline"><strong>l</strong><sup><strong>′</strong></sup><sub><em>s</em></sub></span>均为有效字符。 <br /><span class="math display">$$
\begin{align*}
\alpha_t(s) = (\alpha_{t-1}(s) + \alpha_{t-1}(s-1) + \alpha_{t-1}(s-2)) \cdot p_t(\mathbf{l^\prime}_{1:s}|X)
\end{align*}
$$</span><br /> 通过递推表达式，我们可以表示出整串序列的表达式， <br /><span class="math display">$$
\begin{align*}
p({\mathbf{l}|\mathbf{x}}) = \alpha_T(|\mathbf{l^\prime}|) + \alpha_T(|\mathbf{l^\prime}|-1)
\end{align*}
$$</span><br /></p>
<h1 id="训练方式">训练方式</h1>
<p>本文在注意力解码模型(Attention Decoder)的基础上结合CTC，目的是为了利用CTC用来帮助对齐长序列。因此，目标函数可以写作下式： <br /><span class="math display">$$
\begin{align*}
\mathcal{L} = \alpha \mathcal{L}^{ctc} + (1 - \alpha)\mathcal{L}^{att}
\end{align*}
$$</span><br /> 其中，可调节的参数<span class="math inline"><em>α</em> ∈ [0, 1]</span>作为两个任务的相对权重。</p>
<h1 id="注意力">注意力</h1>
<p>注意力（Attention）是一种权重的矩阵，根据Attention is all you need的定义，An attention function can be described as mapping a query and a set of key-value pairs to an output。其中，输出由加权的value得到，权重根据query和相对应的key通过函数计算得到。</p>
<p>基于内容的注意力机制的表达式的变量中包括<span class="math inline"><em>h</em></span>和<span class="math inline"><em>s</em><sub><em>i</em> − 1</sub></span>。其表达式为 <br /><span class="math display">$$
\begin{align*}
\alpha_i = Attend(s_{i-1}
, h_t)
\end{align*}
$$</span><br /></p>
<p>基于位置的注意力机制表达式的变量包括<span class="math inline"><em>s</em><sub><em>i</em> − 1</sub></span>和<span class="math inline"><em>α</em><sub><em>i</em> − 1</sub></span>。其表达式为 <br /><span class="math display">$$
\begin{align*}
\alpha_i=Attend(s_{i-1}, \alpha_{i-1})
\end{align*}
$$</span><br /></p>
<p>Attention机制通过概率的链式法则直接估计后验概率 <br /><span class="math display">$$
\begin{align*}
p(\mathbf{y}|\mathbf{x})=\prod_{i=1}^Lp(y_i|y_1,...,y_{i-1}, \mathbf{x})
\end{align*}
$$</span><br /> 为了计算<span class="math inline"><em>p</em>(<em>y</em><sub><em>i</em></sub>|<em>y</em><sub>1</sub>, ..., <em>y</em><sub><em>i</em> − 1</sub>, <strong>x</strong>)</span>，可以通过下式得到 <br /><span class="math display">$$
\begin{align*}
    \mathbf{h}_t &amp;= Encoder(\mathbf{x}) \\
    a_{it}&amp;= LocationAttention(\{a_{i-1}\}_{t=1}^T, \mathbf{s}_{i-1}, \mathbf{h}_t) \\
    r_i &amp;= \sum_{t=1}^Ta_{it}h_t \\
    p(y_i|y_1,...,y_{i-1}, \mathbf{x})&amp;=Decoder(\mathbf{r}_i,\mathbf{s}_{i-1},c_{i-1})
\end{align*}
$$</span><br /> 其中，<span class="math inline"><strong>h</strong></span>为解码输出的特征序列，<span class="math inline"><strong>s</strong></span>为hidden vector。解码结合了注意力机制和CTC机制，相比较单一的注意力机制模型，该解码不仅考虑到对齐的单调性，也考虑到了解码过程中容易过早检测到end of sentence 符号结束而失去准确性，原因可以参考<a href="https://www.clsp.jhu.edu/wp-content/uploads/sites/75/2018/06/lecture_advanced_v2.pdf">这里</a>。</p>
<h1 id="语言模型">语言模型</h1>
<p>在推断上我们加入递归神经网络语言模型（RNN-LM），相比较<span class="math inline"><em>n</em></span>-gram 语言模型（<span class="math inline"><em>n</em></span>-gram LM），递归神经网络语言模型可以更好地降低错词率。 语言模型的概率和CTT/Attention的概率结合作为推断下一个字符的分数。其表达式可以写作：</p>
<h1 id="参考文献">参考文献</h1>
<p><sub><a href="https://distill.pub/2017/ctc/">A. Hannun, “Sequence modeling with ctc.”</a></sub></p>
<p><sub><a href="https://arxiv.org/pdf/1506.07503.pdf">Chorowski, Jan K., et al. “Attention-based models for speech recognition.”</a></sub></p>
<p><sub><a href="https://www.merl.com/publications/docs/TR2017-190.pdf">Watanabe, Shinji, et al. “Hybrid CTC/attention architecture for end-to-end speech recognition.”</a></sub></p>
<p><sub><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.6306&amp;rep=rep1&amp;type=pdf">Graves, Alex, et al. “Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks.”</a></sub></p>

<div class="info">Posted by Pingchuan Ma </div>

        </article>


    </body>
</html>
